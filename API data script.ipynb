{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "markdown",
			"source": "#### Optional: Run this cell to see available notebook commands (\"magics\").\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%help",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "markdown",
			"source": "####  Run this cell to set up and start your interactive session.\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 5\n\n",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 6d63a357-6829-45d9-8e99-6db65b5e2131.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Current idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 6d63a357-6829-45d9-8e99-6db65b5e2131.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Setting Glue version to: 4.0\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 6d63a357-6829-45d9-8e99-6db65b5e2131.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous worker type: G.1X\nSetting new worker type to: G.1X\n",
					"output_type": "stream"
				},
				{
					"name": "stderr",
					"text": "You are already connected to a glueetl session 6d63a357-6829-45d9-8e99-6db65b5e2131.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n",
					"output_type": "stream"
				},
				{
					"name": "stdout",
					"text": "Previous number of workers: 5\nSetting new number of workers to: 5\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom awsglue.dynamicframe import DynamicFrame\nimport pandas as pd\nimport requests\nimport json\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 130,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Create a DynamicFrame from a table in the AWS Glue Data Catalog and display its schema\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "dyf = glueContext.create_dynamic_frame.from_catalog(database='f1_target_db', table_name='races')\ndyf.printSchema()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 11,
			"outputs": [
				{
					"name": "stdout",
					"text": "root\n|-- raceid: long\n|-- round: long\n|-- circuitid: long\n|-- name: string\n|-- date: string\n|-- time: string\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "markdown",
			"source": "#### Example: Convert the DynamicFrame to a Spark DataFrame and display a sample of the data\n",
			"metadata": {
				"editable": true,
				"trusted": true
			}
		},
		{
			"cell_type": "code",
			"source": "spark_df = dyf.toDF()\nspark_df.show()",
			"metadata": {
				"trusted": true,
				"editable": true
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "+------+-----+---------+--------------------+----------+--------+\n|raceid|round|circuitid|                name|      date|    time|\n+------+-----+---------+--------------------+----------+--------+\n|     1|    1|        1|Australian Grand ...|2009-03-29|06:00:00|\n|     2|    2|        2|Malaysian Grand Prix|2009-04-05|09:00:00|\n|     3|    3|       17|  Chinese Grand Prix|2009-04-19|07:00:00|\n|     4|    4|        3|  Bahrain Grand Prix|2009-04-26|12:00:00|\n|     5|    5|        4|  Spanish Grand Prix|2009-05-10|12:00:00|\n|     6|    6|        6|   Monaco Grand Prix|2009-05-24|12:00:00|\n|     7|    7|        5|  Turkish Grand Prix|2009-06-07|12:00:00|\n|     8|    8|        9|  British Grand Prix|2009-06-21|12:00:00|\n|     9|    9|       20|   German Grand Prix|2009-07-12|12:00:00|\n|    10|   10|       11|Hungarian Grand Prix|2009-07-26|12:00:00|\n|    11|   11|       12| European Grand Prix|2009-08-23|12:00:00|\n|    12|   12|       13|  Belgian Grand Prix|2009-08-30|12:00:00|\n|    13|   13|       14|  Italian Grand Prix|2009-09-13|12:00:00|\n|    14|   14|       15|Singapore Grand Prix|2009-09-27|12:00:00|\n|    15|   15|       22| Japanese Grand Prix|2009-10-04|05:00:00|\n|    16|   16|       18|Brazilian Grand Prix|2009-10-18|16:00:00|\n|    17|   17|       24|Abu Dhabi Grand Prix|2009-11-01|11:00:00|\n|    18|    1|        1|Australian Grand ...|2008-03-16|04:30:00|\n|    19|    2|        2|Malaysian Grand Prix|2008-03-23|07:00:00|\n|    20|    3|        3|  Bahrain Grand Prix|2008-04-06|11:30:00|\n+------+-----+---------+--------------------+----------+--------+\nonly showing top 20 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Convert spark df to pandas\ndf = dyf.toDF().toPandas()\ndf['date'] = pd.to_datetime(df['date'])\ndf.head()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 23,
			"outputs": [
				{
					"name": "stdout",
					"text": "   raceid  round  circuitid                   name        date      time\n0       1      1          1  Australian Grand Prix  2009-03-29  06:00:00\n1       2      2          2   Malaysian Grand Prix  2009-04-05  09:00:00\n2       3      3         17     Chinese Grand Prix  2009-04-19  07:00:00\n3       4      4          3     Bahrain Grand Prix  2009-04-26  12:00:00\n4       5      5          4     Spanish Grand Prix  2009-05-10  12:00:00\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "existing_rounds_2024 = df[df['date'].dt.year == 2024]['round'].unique()\nlist(existing_rounds_2024)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 92,
			"outputs": [
				{
					"name": "stdout",
					"text": "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "def get_2024_races_data(exclude_rounds = []):\n    response = requests.get(url='https://ergast.com/api/f1/2024.json')\n    races_2024_df = pd.DataFrame.from_dict(response.json()['MRData']['RaceTable']['Races'])\n    races_2024_df['round'] = races_2024_df['round'].astype(int)\n    races_2024_df.drop(columns=['url', 'season', 'FirstPractice', 'SecondPractice', 'ThirdPractice', 'Qualifying', 'Sprint', 'Circuit'], inplace=True)\n\n    return races_2024_df[~races_2024_df['round'].isin(exclude_rounds)]",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 123,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "new_races = get_2024_races_data()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 124,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "new_races_spark = spark.createDataFrame(new_races)\nnew_races_spark.show()",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 125,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-----+--------------------+----------+---------+\n|round|            raceName|      date|     time|\n+-----+--------------------+----------+---------+\n|    1|  Bahrain Grand Prix|2024-03-02|15:00:00Z|\n|    2|Saudi Arabian Gra...|2024-03-09|17:00:00Z|\n|    3|Australian Grand ...|2024-03-24|04:00:00Z|\n|    4| Japanese Grand Prix|2024-04-07|05:00:00Z|\n|    5|  Chinese Grand Prix|2024-04-21|07:00:00Z|\n|    6|    Miami Grand Prix|2024-05-05|20:00:00Z|\n|    7|Emilia Romagna Gr...|2024-05-19|13:00:00Z|\n|    8|   Monaco Grand Prix|2024-05-26|13:00:00Z|\n|    9| Canadian Grand Prix|2024-06-09|18:00:00Z|\n|   10|  Spanish Grand Prix|2024-06-23|13:00:00Z|\n|   11| Austrian Grand Prix|2024-06-30|13:00:00Z|\n|   12|  British Grand Prix|2024-07-07|14:00:00Z|\n|   13|Hungarian Grand Prix|2024-07-21|13:00:00Z|\n|   14|  Belgian Grand Prix|2024-07-28|13:00:00Z|\n|   15|    Dutch Grand Prix|2024-08-25|13:00:00Z|\n|   16|  Italian Grand Prix|2024-09-01|13:00:00Z|\n|   17|Azerbaijan Grand ...|2024-09-15|11:00:00Z|\n|   18|Singapore Grand Prix|2024-09-22|12:00:00Z|\n|   19|United States Gra...|2024-10-20|19:00:00Z|\n|   20|Mexico City Grand...|2024-10-27|20:00:00Z|\n+-----+--------------------+----------+---------+\nonly showing top 20 rows\n\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "new_races_dynamic_frame = DynamicFrame.fromDF(new_races_spark, glueContext, 'new_races')\nglueContext.write_dynamic_frame.from_options(\n    frame=new_races_dynamic_frame,\n    connection_type=\"s3\",\n    connection_options={\"path\": 's3://ie6750-f1-dwh/new_races/new_races.csv'},\n    format=\"csv\"\n)",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": null,
			"outputs": []
		},
		{
			"cell_type": "code",
			"source": "job.commit()",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}